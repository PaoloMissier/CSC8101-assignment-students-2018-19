{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Ratings Predictor with Tensorflow.\n",
    "\n",
    "Ratings predictor for MovieLens dataset with Alternating Least Squares (ALS) model\n",
    "\n",
    "ALS algorithm considers a matrix R of users rating movies, which has m-users rows and n-items columns (m-users x n-items). This matrix should be transformed in 2 matrices: U which has m-users x k-recommendations and P with n-items x k-recommendations, so if we multiply U and P it approximates to R.\n",
    "\n",
    "This work imports the dataset and pre-process it to transform it into that matrix R that then will be factorized to obtain the U and P matrices. \n",
    "Note that Matrices R, U and P constitute the Machine Learning model for the recommendation system.\n",
    "\n",
    "#### References\n",
    "\n",
    "[1] Tak√°cs, G. and Tikk, D. (2012). Alternating least squares for personalized ranking. Proceedings of the sixth ACM conference on Recommender systems - RecSys '12. [online] Available at: https://www.researchgate.net/publication/254464370_Alternating_least_squares_for_personalized_ranking [Accessed 18 Dec. 2018]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserID</th>\n",
       "      <th>MovieID</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>661</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>914</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3408</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2355</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1197</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>1287</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>2804</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>594</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>919</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>595</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>938</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>2398</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>2918</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>1035</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>2791</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>2687</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>2018</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>3105</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>2797</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>2321</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>720</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>1270</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>527</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>2340</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>1097</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>1721</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>1545</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1</td>\n",
       "      <td>745</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000179</th>\n",
       "      <td>6040</td>\n",
       "      <td>2762</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000180</th>\n",
       "      <td>6040</td>\n",
       "      <td>1036</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000181</th>\n",
       "      <td>6040</td>\n",
       "      <td>508</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000182</th>\n",
       "      <td>6040</td>\n",
       "      <td>1041</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000183</th>\n",
       "      <td>6040</td>\n",
       "      <td>3735</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000184</th>\n",
       "      <td>6040</td>\n",
       "      <td>2791</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000185</th>\n",
       "      <td>6040</td>\n",
       "      <td>2794</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000186</th>\n",
       "      <td>6040</td>\n",
       "      <td>527</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000187</th>\n",
       "      <td>6040</td>\n",
       "      <td>2003</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000188</th>\n",
       "      <td>6040</td>\n",
       "      <td>535</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000189</th>\n",
       "      <td>6040</td>\n",
       "      <td>2010</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000190</th>\n",
       "      <td>6040</td>\n",
       "      <td>2011</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000191</th>\n",
       "      <td>6040</td>\n",
       "      <td>3751</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000192</th>\n",
       "      <td>6040</td>\n",
       "      <td>2019</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000193</th>\n",
       "      <td>6040</td>\n",
       "      <td>541</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000194</th>\n",
       "      <td>6040</td>\n",
       "      <td>1077</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000195</th>\n",
       "      <td>6040</td>\n",
       "      <td>1079</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000196</th>\n",
       "      <td>6040</td>\n",
       "      <td>549</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000197</th>\n",
       "      <td>6040</td>\n",
       "      <td>2020</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000198</th>\n",
       "      <td>6040</td>\n",
       "      <td>2021</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000199</th>\n",
       "      <td>6040</td>\n",
       "      <td>2022</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000200</th>\n",
       "      <td>6040</td>\n",
       "      <td>2028</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000201</th>\n",
       "      <td>6040</td>\n",
       "      <td>1080</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000202</th>\n",
       "      <td>6040</td>\n",
       "      <td>1089</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000203</th>\n",
       "      <td>6040</td>\n",
       "      <td>1090</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000204</th>\n",
       "      <td>6040</td>\n",
       "      <td>1091</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000205</th>\n",
       "      <td>6040</td>\n",
       "      <td>1094</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000206</th>\n",
       "      <td>6040</td>\n",
       "      <td>562</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000207</th>\n",
       "      <td>6040</td>\n",
       "      <td>1096</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000208</th>\n",
       "      <td>6040</td>\n",
       "      <td>1097</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000209 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserID</th>\n",
       "      <th>MovieID</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>661</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>914</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3408</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2355</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1197</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>1287</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>2804</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>594</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>919</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>595</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>938</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>2398</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>2918</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>1035</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>2791</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>2687</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>2018</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>3105</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>2797</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>2321</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>720</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>1270</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>527</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>2340</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>1097</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>1721</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>1545</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1</td>\n",
       "      <td>745</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000179</th>\n",
       "      <td>6040</td>\n",
       "      <td>2762</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000180</th>\n",
       "      <td>6040</td>\n",
       "      <td>1036</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000181</th>\n",
       "      <td>6040</td>\n",
       "      <td>508</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000182</th>\n",
       "      <td>6040</td>\n",
       "      <td>1041</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000183</th>\n",
       "      <td>6040</td>\n",
       "      <td>3735</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000184</th>\n",
       "      <td>6040</td>\n",
       "      <td>2791</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000185</th>\n",
       "      <td>6040</td>\n",
       "      <td>2794</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000186</th>\n",
       "      <td>6040</td>\n",
       "      <td>527</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000187</th>\n",
       "      <td>6040</td>\n",
       "      <td>2003</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000188</th>\n",
       "      <td>6040</td>\n",
       "      <td>535</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000189</th>\n",
       "      <td>6040</td>\n",
       "      <td>2010</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000190</th>\n",
       "      <td>6040</td>\n",
       "      <td>2011</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000191</th>\n",
       "      <td>6040</td>\n",
       "      <td>3751</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000192</th>\n",
       "      <td>6040</td>\n",
       "      <td>2019</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000193</th>\n",
       "      <td>6040</td>\n",
       "      <td>541</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000194</th>\n",
       "      <td>6040</td>\n",
       "      <td>1077</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000195</th>\n",
       "      <td>6040</td>\n",
       "      <td>1079</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000196</th>\n",
       "      <td>6040</td>\n",
       "      <td>549</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000197</th>\n",
       "      <td>6040</td>\n",
       "      <td>2020</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000198</th>\n",
       "      <td>6040</td>\n",
       "      <td>2021</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000199</th>\n",
       "      <td>6040</td>\n",
       "      <td>2022</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000200</th>\n",
       "      <td>6040</td>\n",
       "      <td>2028</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000201</th>\n",
       "      <td>6040</td>\n",
       "      <td>1080</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000202</th>\n",
       "      <td>6040</td>\n",
       "      <td>1089</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000203</th>\n",
       "      <td>6040</td>\n",
       "      <td>1090</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000204</th>\n",
       "      <td>6040</td>\n",
       "      <td>1091</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000205</th>\n",
       "      <td>6040</td>\n",
       "      <td>1094</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000206</th>\n",
       "      <td>6040</td>\n",
       "      <td>562</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000207</th>\n",
       "      <td>6040</td>\n",
       "      <td>1096</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000208</th>\n",
       "      <td>6040</td>\n",
       "      <td>1097</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000209 rows √ó 3 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 0,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from IPython.display import display\n",
    "from scipy.sparse import coo_matrix\n",
    "\n",
    "DATA = \"data/movielens_1m/\"\n",
    "\n",
    "def open_dataset(dataset_name, fields, given_encoding):\n",
    "    dataset_path = DATA + dataset_name + \".dat\"\n",
    "    dataframe = pd.read_csv(dataset_path, sep='::', names=fields, header=None, encoding=given_encoding, engine='python')\n",
    "    return dataframe\n",
    "    \n",
    "# Importing the ratings dataset into a Pandas DataFrame.\n",
    "ratings_df = open_dataset(\"ratings\", [\"UserID\",\"MovieID\",\"Rating\",\"TimeStamp\"], \"utf-8\")\n",
    "\n",
    "# Removing the Timestamp column since we would not need it.\n",
    "ratings_df = ratings_df.drop(['TimeStamp'], axis=1)\n",
    "display(ratings_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Pre-processing: Converting data frame to Matrix.\n",
    "\n",
    "Here we'll convert the current ratings dataframe to a matrix with 0-based indexing so it can be processed easily by Tensorflow. Here we'll be normalizing the matrices. Also we'll be creating the user_map (represents the U matrix) and movies_map (represents the P matrix), which will be the matrix factors that constitute the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/human/l/_PGR_NCL/BigData/dev/community_scanner/venv/lib/python3.5/site-packages/ipykernel_launcher.py:2: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n  \n"
     ]
    }
   ],
   "source": [
    "#---Mapping item ratings matrix.\n",
    "ratings = ratings_df.as_matrix([\"UserID\", \"MovieID\", \"Rating\"])\n",
    "ratings[:,0] -= 1\n",
    "ratings[:,1] -= 1\n",
    "\n",
    "users_map = ratings[:,0]\n",
    "movies_map = ratings[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Defining Training and test sets.\n",
    "\n",
    "\n",
    "Here using the newly mapped ratings we'll define the training sets and test sets. We'll use the 90% of the dataset as the training set and the remaining 10% as the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 3407)\t4\n  (0, 594)\t5\n  (0, 1034)\t5\n  (0, 2790)\t4\n  (0, 2017)\t4\n  (0, 2320)\t3\n  (0, 3185)\t4\n  (0, 1028)\t5\n  (1, 1356)\t5\n  (1, 1791)\t3\n  (1, 3029)\t4\n  (1, 367)\t4\n  (1, 2851)\t3\n  (1, 2027)\t4\n  (1, 1197)\t4\n  (1, 1123)\t5\n  (1, 162)\t4\n  (1, 20)\t1\n  (1, 2500)\t5\n  (1, 3677)\t3\n  (1, 1243)\t3\n  (1, 355)\t5\n  (1, 1244)\t2\n  (2, 2996)\t3\n  (2, 1290)\t4\n  :\t:\n  (6039, 212)\t5\n  (6039, 1833)\t4\n  (6039, 231)\t5\n  (6039, 259)\t4\n  (6039, 2857)\t4\n  (6039, 3818)\t5\n  (6039, 1135)\t4\n  (6039, 1187)\t4\n  (6039, 1188)\t5\n  (6039, 2145)\t1\n  (6039, 1899)\t5\n  (6039, 1911)\t3\n  (6039, 1920)\t4\n  (6039, 317)\t4\n  (6039, 1944)\t5\n  (6039, 1951)\t5\n  (6039, 1234)\t4\n  (6039, 1258)\t3\n  (6039, 1284)\t4\n  (6039, 3288)\t5\n  (6039, 447)\t4\n  (6039, 1718)\t5\n  (6039, 2749)\t2\n  (6039, 3702)\t4\n  (6039, 2018)\t5\n"
     ]
    }
   ],
   "source": [
    "# We'll use the 10% of the dataset as the test set.\n",
    "test_set_size = int(len(ratings) / 10)\n",
    "\n",
    "test_set_idx = np.random.choice(range(len(ratings)), size=test_set_size, replace=False)\n",
    "\n",
    "test_set_idx = sorted(test_set_idx)\n",
    "\n",
    "ts_ratings = ratings[test_set_idx]\n",
    "\n",
    "tr_ratings = np.delete(ratings, test_set_idx, axis=0)\n",
    "\n",
    "# Training sets.\n",
    "u_tr, m_tr, r_tr = zip(*tr_ratings)\n",
    "\n",
    "# Test sets.\n",
    "u_ts, m_ts, r_ts = zip(*ts_ratings)\n",
    "\n",
    "# Training sparse coordinate matrix.\n",
    "tr_sparse = coo_matrix((r_tr, (u_tr, m_tr)), shape=(len(u_tr), len(m_tr)))\n",
    "\n",
    "# Test sparse coordinate matrix.\n",
    "ts_sparse = coo_matrix((r_ts, (u_ts, m_ts)), shape=(len(u_ts), len(m_ts)))\n",
    "print(ts_sparse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Implementing WALS (Weighted Alternate Least Squares) in Tensorflow\n",
    "\n",
    "Weighted Alternate Least Squares is the implementation of the ALS algorithm in Tensorflow.\n",
    "\n",
    "Implementation based on this tutorial: https://cloud.google.com/solutions/machine-learning/recommendation-system-tensorflow-create-model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def train_model(args, tr_sparse):\n",
    "    '''\n",
    "    Based on: https://github.com/GoogleCloudPlatform/training-data-analyst/blob/master/courses/machine_learning/deepdive/10_recommend/endtoend/wals_ml_engine/trainer/wals.py#L46\n",
    "    '''\n",
    "    \n",
    "    # Getting parameters.\n",
    "    dim = args['latent_factors']\n",
    "    num_iters = args['num_iters']\n",
    "    reg = args['regularization']\n",
    "    unobs = args['unobs_weight']\n",
    "    wt_type = args['wt_type']\n",
    "    feature_wt_exp = args['feature_wt_exp']\n",
    "    obs_wt = args['feature_wt_factor']\n",
    "    col_wts = args['column_weights']\n",
    "    row_wts = args['row_weights']\n",
    "    \n",
    "    # Generating the input tensor.\n",
    "    input_tensor = tf.SparseTensor(indices=list(zip(tr_sparse.row, tr_sparse.col)), values=(tr_sparse.data).astype(np.float32), dense_shape=tr_sparse.shape)\n",
    "    \n",
    "    # Generating the model.\n",
    "    model = tf.contrib.factorization.WALSModel(tr_sparse.shape[0], tr_sparse.shape[1], dim, unobserved_weight=unobs, regularization=reg, row_weights=row_wts, col_weights=col_wts)\n",
    "    \n",
    "    row_factor = model.row_factors[0]\n",
    "    col_factor = model.col_factors[0]\n",
    "    \n",
    "    # Training the model.\n",
    "    sess = tf.Session(graph=input_tensor.graph)\n",
    "    \n",
    "    with input_tensor.graph.as_default():\n",
    "        row_update_op = model.update_row_factors(sp_input=input_tensor)[1]\n",
    "        col_update_op = model.update_col_factors(sp_input=input_tensor)[1]\n",
    "    \n",
    "        sess.run(model.initialize_op)\n",
    "        sess.run(model.worker_init)\n",
    "\n",
    "        for _ in range(num_iters):\n",
    "            sess.run(model.row_update_prep_gramian_op)\n",
    "            sess.run(model.initialize_row_update_op)\n",
    "            sess.run(row_update_op)\n",
    "            sess.run(model.col_update_prep_gramian_op)\n",
    "            sess.run(model.initialize_col_update_op)\n",
    "            sess.run(col_update_op)\n",
    "            \n",
    "    \n",
    "    out_row = row_factor.eval(session=sess)\n",
    "    out_col = col_factor.eval(session=sess)\n",
    "    \n",
    "    # After evaluating the output we close the training session.\n",
    "    sess.close()\n",
    "    \n",
    "    # Out_row: users, out_col: items. Row_factor: out_row before training, Col_factor: out_col before training.\n",
    "    return out_row, out_col, row_factor, col_factor\n",
    "        \n",
    "    \n",
    "\n",
    "def generate_recommendations(user_ids, user_rated, row_factor, col_factor, num_recommendations):\n",
    "    '''\n",
    "    user_rated: indices.\n",
    "    Code based on: https://github.com/GoogleCloudPlatform/training-data-analyst/blob/master/courses/machine_learning/deepdive/10_recommend/endtoend/wals_ml_engine/trainer/model.py#L325\n",
    "    '''\n",
    "    \n",
    "    assert(row_factor.shape[0] - len(user_rated)) >= num_recommendations\n",
    "    \n",
    "    # Retrieve the user factor.\n",
    "    user_factor = row_factor[user_ids]\n",
    "    \n",
    "    # Dot product of item factors with user factor gives predicted ratings.\n",
    "    predicted_ratings = col_factor.dot(user_factor)\n",
    "    \n",
    "    # Find candidate recommended item indexes sorted by predicted ratings.\n",
    "    num_recomm = num_recommendations + len(user_rated)\n",
    "    candidate_items = np.argsort(predicted_ratings)[-num_recomm:]\n",
    "    \n",
    "    # Remove previously rated items and take top k\n",
    "    recommended_items = [i for i in candidate_items if i not in user_rated]\n",
    "    recommended_items = recommended_items[-num_recommendations:]\n",
    "    \n",
    "    # Flip to sort the highest rated first.\n",
    "    recommended_items.reverse()\n",
    "    \n",
    "    return recommended_items\n",
    "\n",
    "\n",
    "\n",
    "def make_weights(data, weight_type, obs_weight, feature_wt_exp, axis):\n",
    "    '''\n",
    "    Obtained from: https://github.com/GoogleCloudPlatform/training-data-analyst/blob/master/courses/machine_learning/deepdive/10_recommend/endtoend/wals_ml_engine/trainer/task.py\n",
    "    '''\n",
    "    \n",
    "    # Recipricol of sum of number of items across rows (if axis is 0)\n",
    "    frac = np.array(1.0/(data > 0.0).sum(axis))\n",
    "    \n",
    "    # Filter any invalid entries\n",
    "    frac[np.ma.masked_invalid(frac).mask] = 0.0\n",
    "    \n",
    "    # Normalize weights according to assumed distribution of ratings\n",
    "    if weight_type == 0:\n",
    "        wts = np.array(np.power(frac, feature_wt_exp)).flatten()\n",
    "    else:\n",
    "        wts = np.array(obs_weight * frac).flatten()\n",
    "\n",
    "    # check again for any numerically unstable entries\n",
    "    assert np.isfinite(wts).sum() == wts.shape[0]\n",
    "    return wts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Training WALS model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/human/l/_PGR_NCL/BigData/dev/community_scanner/venv/lib/python3.5/site-packages/ipykernel_launcher.py:91: RuntimeWarning: divide by zero encountered in true_divide\n"
     ]
    }
   ],
   "source": [
    "# Defining initial parameters.\n",
    "\n",
    "# Defining weights for WALS model.\n",
    "col_wts = make_weights(tr_sparse, 0, 100.0, 0.08, 0)\n",
    "row_wts = make_weights(tr_sparse, 0, 100.0, 0.08, 1)\n",
    "\n",
    "INITIAL_PARAMS = {\n",
    "    \"weights\": True,\n",
    "    \"latent_factors\": 34,\n",
    "    \"num_iters\": 20,\n",
    "    \"regularization\": 9.83,\n",
    "    \"unobs_weight\": 0.001,\n",
    "    \"wt_type\": 0,\n",
    "    \"feature_wt_factor\": 189.8,\n",
    "    \"feature_wt_exp\": 0.08,\n",
    "    \"column_weights\": col_wts,\n",
    "    \"row_weights\": row_wts\n",
    "}\n",
    "\n",
    "output_row, output_col, r_factor, c_factor = train_model(INITIAL_PARAMS, tr_sparse)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Calculate RMSE\n",
    "\n",
    "Calculate the Root Mean Squared Error to see the algorithm prediction performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7520542928348384\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.748865055205765\n"
     ]
    }
   ],
   "source": [
    "def calculate_rmse(out_row, out_col, actual):\n",
    "    '''\n",
    "    Obtained from: https://github.com/GoogleCloudPlatform/training-data-analyst/blob/master/courses/machine_learning/deepdive/10_recommend/endtoend/wals_ml_engine/trainer/wals.py#L24\n",
    "    '''\n",
    "    mse = 0\n",
    "    \n",
    "    for i in range(actual.data.shape[0]):\n",
    "        row_pred = out_row[actual.row[i]]\n",
    "        col_pred = out_col[actual.col[i]]\n",
    "        err = actual.data[i] - np.dot(row_pred, col_pred)\n",
    "        mse += err * err\n",
    "        \n",
    "    mse /= actual.data.shape[0]\n",
    "    rmse = np.sqrt(mse)\n",
    "    \n",
    "    return rmse\n",
    "\n",
    "# Evaluating training performance.\n",
    "train_rmse = calculate_rmse(output_row, output_col, tr_sparse)\n",
    "print(train_rmse)\n",
    "\n",
    "# Evaluating test performance.\n",
    "test_rmse = calculate_rmse(output_row, output_col, ts_sparse)\n",
    "print(test_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Generating recommendations with WALS model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23145, 441293, 727418, 641859, 628451]\n"
     ]
    }
   ],
   "source": [
    "n_recommendations = 5\n",
    "# User id: 3\n",
    "user_idx = np.searchsorted(users_map, 3)\n",
    "\n",
    "# Taken from training set, but we can use the test set as well.\n",
    "already_rated_by_user = [2355, 1197, 1287]\n",
    "\n",
    "# Indices where already_rated_by_user movies are in the movies_map\n",
    "indices_user_rated_movies = [np.searchsorted(movies_map, i) for i in already_rated_by_user]\n",
    "\n",
    "recommendations = generate_recommendations(user_idx, indices_user_rated_movies, output_row, output_col, n_recommendations)\n",
    "\n",
    "# Movies ID recommended for user_id: 3.\n",
    "print(recommendations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
